{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `flarestack` Test Minimization Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Directory Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level='INFO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/thomasahrens/Desktop/IceCube/flarestack/scratch'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['FLARESTACK_SCRATCH_DIR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flarestack.shared:Scratch Directory is: /Users/thomasahrens/Desktop/IceCube/flarestack/scratch/flarestack__data/\n",
      "INFO:flarestack.shared:Found Directory: /Users/thomasahrens/Desktop/IceCube/flarestack/scratch/flarestack__data/\n",
      "INFO:flarestack.shared:Found Directory: /Users/thomasahrens/Desktop/IceCube/flarestack/scratch/flarestack__data/input/\n",
      "INFO:flarestack.shared:Found Directory: /Users/thomasahrens/Desktop/IceCube/flarestack/scratch/flarestack__data/storage/\n",
      "INFO:flarestack.shared:Found Directory: /Users/thomasahrens/Desktop/IceCube/flarestack/scratch/flarestack__data/output/\n",
      "INFO:flarestack.shared:Found Directory: /Users/thomasahrens/Desktop/IceCube/flarestack/scratch/flarestack__data/cluster/\n",
      "INFO:flarestack.shared:Found Directory: /Users/thomasahrens/Desktop/IceCube/flarestack/scratch/flarestack__data/input/pull_corrections/\n",
      "INFO:flarestack.shared:Found Directory: /Users/thomasahrens/Desktop/IceCube/flarestack/scratch/flarestack__data/cluster/logs/\n",
      "INFO:flarestack.shared:Found Directory: /Users/thomasahrens/Desktop/IceCube/flarestack/scratch/flarestack__data/input/catalogues/\n",
      "INFO:flarestack.shared:Found Directory: /Users/thomasahrens/Desktop/IceCube/flarestack/scratch/flarestack__data/input/acceptance_functions/\n",
      "INFO:flarestack.shared:Found Directory: /Users/thomasahrens/Desktop/IceCube/flarestack/scratch/flarestack__data/input/energy_pdf_splines/\n",
      "INFO:flarestack.shared:Found Directory: /Users/thomasahrens/Desktop/IceCube/flarestack/scratch/flarestack__data/storage/pickles/\n",
      "INFO:flarestack.shared:Found Directory: /Users/thomasahrens/Desktop/IceCube/flarestack/scratch/flarestack__data/output/plots/\n",
      "INFO:flarestack.shared:Found Directory: /Users/thomasahrens/Desktop/IceCube/flarestack/scratch/flarestack__data/input/SoB_splines/\n",
      "INFO:flarestack.shared:Found Directory: /Users/thomasahrens/Desktop/IceCube/flarestack/scratch/flarestack__data/input/analysis/\n",
      "INFO:flarestack.shared:Found Directory: /Users/thomasahrens/Desktop/IceCube/flarestack/scratch/flarestack__data/output/plots/illustrations/\n",
      "INFO:flarestack.shared:Found Directory: /Users/thomasahrens/Desktop/IceCube/flarestack/scratch/flarestack__data/input/catalogues/transients/\n",
      "INFO:flarestack.shared:Found Directory: /Users/thomasahrens/Desktop/IceCube/flarestack/scratch/flarestack__data/input/bkg_splines/\n",
      "INFO:flarestack.shared:Found Directory: /Users/thomasahrens/Desktop/IceCube/flarestack/scratch/flarestack__data/output/dataset_plots/\n",
      "INFO:flarestack.shared:Found Directory: /Users/thomasahrens/Desktop/IceCube/flarestack/scratch/flarestack__data/output/unblinding_results/\n",
      "INFO:flarestack.shared:Found Directory: /Users/thomasahrens/Desktop/IceCube/flarestack/scratch/flarestack__data/output/limits/\n",
      "INFO:flarestack.shared:Found Directory: /Users/thomasahrens/Desktop/IceCube/flarestack/scratch/flarestack__data/input/pull_corrections/pulls/\n",
      "INFO:flarestack.shared:Found Directory: /Users/thomasahrens/Desktop/IceCube/flarestack/scratch/flarestack__data/input/pull_corrections/floors/\n",
      "INFO:flarestack.shared:Found Directory: /Users/thomasahrens/Desktop/IceCube/flarestack/scratch/flarestack__data/storage/cache/\n",
      "INFO:flarestack.shared:Found Directory: /Users/thomasahrens/Desktop/IceCube/flarestack/scratch/flarestack__data/storage/cache/catalogue_cache/\n",
      "INFO:flarestack.shared:Found Directory: /Users/thomasahrens/Desktop/IceCube/flarestack/scratch/flarestack__data/input/public_datasets/\n",
      "INFO:flarestack.shared:Found Directory: /Users/thomasahrens/Desktop/IceCube/flarestack/scratch/flarestack__data/input/energy_proxy_weighting/\n",
      "INFO:flarestack.shared:Found Directory: /Users/thomasahrens/Desktop/IceCube/flarestack/scratch/flarestack__data/output/dataset_plots/effective_area_plots/\n",
      "INFO:flarestack.shared:Found Directory: /Users/thomasahrens/Desktop/IceCube/flarestack/scratch/flarestack__data/input/median_angular_resolution/\n",
      "INFO:flarestack.shared:Found Directory: /Users/thomasahrens/Desktop/IceCube/flarestack/scratch/flarestack__data/output/dataset_plots/angular_resolution_plots/\n",
      "INFO:flarestack.shared:Found Directory: /Users/thomasahrens/Desktop/IceCube/flarestack/scratch/flarestack__data/output/dataset_plots/energy_proxy_map/\n",
      "INFO:flarestack.shared:Found Directory: /Users/thomasahrens/Desktop/IceCube/flarestack/scratch/flarestack__data/input/sim_datasets/\n",
      "INFO:numexpr.utils:Note: NumExpr detected 10 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n",
      "INFO:flarestack.data.icecube.ic_season:Loading datasets from /Users/thomasahrens/Desktop/IceCube/flarestack/datasets/ (local)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running at None, data directory is /Users/thomasahrens/Desktop/IceCube/flarestack/datasets/\n"
     ]
    }
   ],
   "source": [
    "from flarestack.shared import host_server\n",
    "from flarestack.data.icecube.ic_season import icecube_dataset_dir\n",
    "print(f'Running at {host_server}, data directory is {icecube_dataset_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scratch directory is /Users/thomasahrens/Desktop/IceCube/flarestack/scratch/flarestack__data/\n"
     ]
    }
   ],
   "source": [
    "from flarestack.shared import fs_scratch_dir\n",
    "print(f'Scratch directory is {fs_scratch_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Flarestack Classes\n",
    "\n",
    "Classes used in $\\texttt{flarestack}$'s core functionality (e.g. `flarestack.core.energy_pdf.EnergyPDF`, `flarestack.core.minimisation.MinimisationHandler`, etc) have a class attribute `<class>.subclasses`.  \n",
    "This is a dictionary with the structure `{<subclass name>: <subclass>}`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fixed_weights': flarestack.core.minimisation.FixedWeightMinimisationHandler,\n",
       " 'large_catalogue': flarestack.core.minimisation.LargeCatalogueMinimisationHandler,\n",
       " 'fit_weights': flarestack.core.minimisation.FitWeightMinimisationHandler,\n",
       " 'fit_weights_mcmc': flarestack.core.minimisation.FitWeightMCMCMinimisationHandler,\n",
       " 'fit_weights_hmc': flarestack.core.minimisation.FitWeightHMCMinimisationHandler,\n",
       " 'flare': flarestack.core.minimisation.FlareMinimisationHandler}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flarestack.core.minimisation import MinimisationHandler\n",
    "MinimisationHandler.subclasses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For analyses we only have to pass a dictionary of the subclass names and corresponding parameters.  \n",
    "To execute use `flarestack.cluster.submitter.Submitter`. This always works locally. For using the cluster, again, if you are running at DESY or WIPAC, you do not have to worry. We got you covered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'local': flarestack.cluster.submitter.LocalSubmitter,\n",
       " 'DESY': flarestack.cluster.submitter.DESYSubmitter,\n",
       " 'WIPAC': flarestack.cluster.submitter.WIPACSubmitter}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flarestack.cluster.submitter import Submitter\n",
    "Submitter.submitter_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Example: Point Source Sensitivity\n",
    "\n",
    "Let's try to calculate the 10-year point source sensitivity for our test catalogue.  \n",
    "The input directory (with the analysis dictionaries), the output directory (plots, p-values, etc) and the cache directory (saved trials, etc) will be created accordingly.   \n",
    "First we have to specify a name for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flarestack.shared import plot_output_dir, name_pickle_output_dir\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_types = ('fixed',  # fixed_weights\n",
    "             'fit',    # fit_weights\n",
    "             'mcmc',   # fit_weights_mcmc\n",
    "             'hmc')    # NotImplemented\n",
    "\n",
    "def name_func(n_sources, gamma, min_type, scale, trials, etc=None):\n",
    "    \"\"\"Creates name for output analysis files. This is motivated\n",
    "    by the need to inspect run results for debugging purposes, \n",
    "    and is achieved by using unique names to refer to each run.\n",
    "    \n",
    "    :param n_sources: Number of sources in catalog\n",
    "    :type n_sources: int\n",
    "    \n",
    "    :param gamma: Spectral index\n",
    "    :type n_sources: float\n",
    "    \n",
    "    :param min_type: Minimization method (see MinimisationHandler.subclasses)\n",
    "    :type n_sources: str\n",
    "    \n",
    "    :param etc: Additional simulation/run info\n",
    "    :type n_sources: str\n",
    "    \n",
    "    :return path: Path used as name\n",
    "    :rtype path: str\n",
    "    \"\"\"\n",
    "    run_no = 1\n",
    "    \n",
    "    if min_type not in min_types:\n",
    "        raise ValueError(f'Provide valid minimizer: {min_types}')\n",
    "        \n",
    "    path = f'analyses/{n_sources}source_gamma{gamma}_{min_type}_{scale}_trials{trials}'\n",
    "    \n",
    "    if etc is not None:\n",
    "        path += f'_{etc:s}'\n",
    "        \n",
    "    path += f'_run{run_no}'\n",
    "    \n",
    "    path_exist = os.path.exists(plot_output_dir(path)) or os.path.exists(name_pickle_output_dir(path))\n",
    "    \n",
    "    if path_exist:\n",
    "        # Automatically covers cases where run_no == (n_sources or gamma)\n",
    "        glob_path = path.split(f'_run{run_no}')[0]\n",
    "        # Get all runs with same path\n",
    "        previous_runs = glob(f'{name_pickle_output_dir(glob_path)}*')\n",
    "        # Get run numbers for previous runs, convert strings to ints\n",
    "        run_nums = [int(i.split('_run')[1]) for i in previous_runs]\n",
    "        # Sort run numbers\n",
    "        run_nums.sort()\n",
    "        # Get last run number, increase index by 1\n",
    "        run_no = run_nums[-1] + 1\n",
    "        path = f'{glob_path}_run{run_no}'\n",
    "    else:\n",
    "        # Path DNE, unchanged path (run 1)\n",
    "        pass\n",
    "    \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'analyses/2source_gamma2.0_mcmc_sumscale_trials10_1season_run2'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = name_func(n_sources=2, gamma=2.0, min_type='mcmc', \n",
    "                 scale='sumscale', trials=10, etc='1season')\n",
    "name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our plot output directories will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/thomasahrens/Desktop/IceCube/flarestack/scratch/flarestack__data/output/plots/analyses/2source_gamma2.0_fit_sumscale_trials10_1season_run1',\n",
       " '/Users/thomasahrens/Desktop/IceCube/flarestack/scratch/flarestack__data/storage/pickles/analyses/2source_gamma2.0_fit_sumscale_trials10_1season_run1')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flarestack.shared import plot_output_dir, name_pickle_output_dir\n",
    "plot_output_dir(name), name_pickle_output_dir(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Public 3-year point source data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('IC79-2010', <flarestack.data.public.icecube.PublicICSeason object at 0x179325c00>)\n",
      "('IC86-2011', <flarestack.data.public.icecube.PublicICSeason object at 0x179325cf0>)\n",
      "('IC86-2012', <flarestack.data.public.icecube.PublicICSeason object at 0x179325db0>)\n"
     ]
    }
   ],
   "source": [
    "# from flarestack.data.icecube import ps_v003_p02\n",
    "from flarestack.data.public import icecube_ps_3_year\n",
    "\n",
    "for item in icecube_ps_3_year.items():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to inject a steady neutrino signal with a power law spectrum with $\\gamma=2.5$. For other Energy or Time PDFs check `flarestack.core.energy_pdf` and `flarestack.core.time_pdf`.   \\\n",
    "This is as straight forward as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "injection_energy = {\n",
    "    \"energy_pdf_name\": \"power_law\",\n",
    "    \"gamma\": 2.0\n",
    "}\n",
    "\n",
    "injection_time = {\n",
    "    \"time_pdf_name\": \"steady\"\n",
    "}\n",
    "\n",
    "inj_kwargs = {\n",
    "    \"injection_energy_pdf\": injection_energy,\n",
    "    \"injection_sig_time_pdf\": injection_time\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are looking for a steady signal with a power law spectrum. \n",
    "We assume the background to be constant in time.  \n",
    "We want to use the \"standard\" point source likelihood. More likelihood implementations in `flarestack.core.llh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "llh_time = {\n",
    "    \"time_pdf_name\": \"steady\"\n",
    "}\n",
    "\n",
    "llh_energy = {\n",
    "    \"energy_pdf_name\": \"power_law\",\n",
    "}\n",
    "\n",
    "llh_time_bkg = {\n",
    "    \"time_pdf_name\": \"steady\"\n",
    "}\n",
    "\n",
    "llh_kwargs = {\n",
    "    \"llh_name\": \"standard\",\n",
    "    \"llh_energy_pdf\": llh_energy,\n",
    "    \"llh_sig_time_pdf\": llh_time,\n",
    "    \"llh_bkg_time_pdf\": llh_time_bkg\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a source catalogue. This catalogue will be a numpy array stored as a `.npy` file and we only pass the filename.   \n",
    "For point sources the is a uitility function to generate dummy sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your catalogue is located at /Users/thomasahrens/Desktop/IceCube/sn-search/catalog/test_catalogue_2.npy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([(0.19872028, -0.24886844, 1., 1., nan, nan, nan, 2.04324986e+13, b'ASASSN-14il'),\n",
       "       (3.67889954, -0.67152028, 1., 1., nan, nan, nan, 1.64885347e+13, b'ASASSN-15ab')],\n",
       "      dtype=[('ra_rad', '<f8'), ('dec_rad', '<f8'), ('base_weight', '<f8'), ('injection_weight_modifier', '<f8'), ('ref_time_mjd', '<f8'), ('start_time_mjd', '<f8'), ('end_time_mjd', '<f8'), ('distance_mpc', '<f8'), ('source_name', 'S30')])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from flarestack.utils.prepare_catalogue import ps_catalogue_name\n",
    "import numpy as np\n",
    "\n",
    "sindec = 0.5\n",
    "catalogue_path = \"/Users/thomasahrens/Desktop/IceCube/sn-search/catalog/test_catalogue_2.npy\"\n",
    "print(f'your catalogue is located at {catalogue_path}')\n",
    "catalogue = np.load(catalogue_path)\n",
    "catalogue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we make a guess for our sensitivity.   \n",
    "Note: $\\texttt{flarestack}$ is using its own scale factor $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999999999.9999999, 1.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flarestack.shared import flux_to_k, k_to_flux\n",
    "flux_to_k(1), flux_to_k(1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we know where the sensitivity should be. Because the analysis has been done before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.24859081, 24.92108471])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logging.basicConfig(level='ERROR')\n",
    "from flarestack.icecube_utils.reference_sensitivity import reference_sensitivity\n",
    "scale = flux_to_k(reference_sensitivity(np.sin(catalogue['dec_rad']))) * 3\n",
    "scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just have to put all the info into one dictionary to pass to the `MinimisationHandler`. Note that our scale guess is informed by the sum over the estimated scales from `flarestack.icecube_utils.reference_sensitivity`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IC79-2010': <flarestack.data.public.icecube.PublicICSeason at 0x179325c00>,\n",
       " 'IC86-2011': <flarestack.data.public.icecube.PublicICSeason at 0x179325cf0>,\n",
       " 'IC86-2012': <flarestack.data.public.icecube.PublicICSeason at 0x179325db0>}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icecube_ps_3_year.seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mh_dict = {\n",
    "    \"name\": name,                                           # unique name for the analysis\n",
    "    \"mh_name\": \"fit_weights_mcmc\",                               # name of the MinimisationHandler subclass\n",
    "    \"dataset\": icecube_ps_3_year.get_seasons('IC79-2010'),             # the neutrino dataset\n",
    "    \"catalogue\": catalogue_path,                            # path to the .npy catalogue file\n",
    "    \"inj_dict\": inj_kwargs,                                 # info for the Injector\n",
    "    \"llh_dict\": llh_kwargs,                                 # info for the LLH\n",
    "    \"scale\": np.sum(scale),                                 # a guess for the sensitivity scale\n",
    "    \"n_trials\": 10,                                         # number of trials to run (background trials will be run ten times this number!)\n",
    "    \"n_steps\": 10,                                          # number of steps when injecting signal\n",
    "    \"allow_extrapolated_sensitivity\": True                  # allow extrapolation in the sensitivity calculation (here we do because we only run very few trials)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To execute the analysis we defined above we create a submitter instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submitter = Submitter.get_submitter(\n",
    "    mh_dict=mh_dict,                         # the analysis info\n",
    "    use_cluster=False,                       # run it on the cluster if True\n",
    "    n_cpu=7,                                # number of LOCAL CPUs to use, NOTE: the number of cluster CPUs has to be specified in the cluster_kwargs!\n",
    "    do_sensitivity_scale_estimation=False,   # make a guess of the sensitivity scale, for options check flarestack.cluster.submitter\n",
    "    remove_old_results=True,                 # if you are running the analysis again and something changed, maybe you want to remove old trials?\n",
    "#   **cluster_kwargs                         # keyword arguments used when running the cluster, This depends on the cluster obviously\n",
    ")\n",
    "\n",
    "print(submitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Energise ......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "submitter.analyse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the results we use the `ResultsHandler()`. This will also create some plots like the sensitivity fit, bias plots, etc. in the plot directory. If `OverfluctuationError`, set `do_sens=False` and `do_disc=False` in `ResultsHandler()` object.\n",
    "\n",
    "```do_sens=False, do_disc=False```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flarestack.core.results import ResultsHandler\n",
    "results_handler = ResultsHandler(submitter.mh_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fr'sensitivity flux: {results_handler.sensitivity:<10.2e} '\n",
    "      fr'+{results_handler.sensitivity_err[1]:<10.2e} '\n",
    "      fr'-{results_handler.sensitivity_err[0]:<10.2e}')\n",
    "print(f'reference: {reference_sensitivity(sindec)[0]:>15.2e}')\n",
    "print(fr'sensitivity n_s:  {results_handler.sensitivity * results_handler.flux_to_ns:<10.2e} '\n",
    "      fr'+{results_handler.sensitivity_err[1] * results_handler.flux_to_ns:<9.4f}  '\n",
    "      fr'-{results_handler.sensitivity_err[0] * results_handler.flux_to_ns:<9.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat analysis using MCMC\n",
    "`n_trials` has been reduced in order to run this notebook more easily, `n_trials = 100` has been used for testing purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find MCMC seed values\n",
    "\n",
    "Seed the MCMC around the maximum LLH fround by the `fit_weights` minimizer. Copy `mu` and `std` lists into MCMC minimizer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def means_and_dev(name):\n",
    "    \"\"\"Calculates mean and standard deviation from `fit_weights` minimizer\n",
    "    to then be input into `fit_weights_mcmc` minimizer.\n",
    "    \n",
    "    :param name: Analysis run name\n",
    "    :type name: str\n",
    "    \n",
    "    :return mu: List of average parameter (n_s, gamma) values\n",
    "    :rtype mu: list\n",
    "    \n",
    "    :return std: List of parameter (n_s, gamma) standard deviations\n",
    "    :rtype std: list\n",
    "    \"\"\"\n",
    "    path_to_pickles = os.path.join(name_pickle_output_dir(name), 'merged')\n",
    "    pickles = glob(os.path.join(path_to_pickles, '*.pkl'))\n",
    "    key_arrays = {}\n",
    "    \n",
    "    for pkl in pickles:\n",
    "        pickle_path = pkl\n",
    "\n",
    "        with open(pickle_path, 'rb') as file:\n",
    "            pickle_data = pickle.load(file)\n",
    "\n",
    "        if not key_arrays:\n",
    "            key_arrays = {key:[] for key in pickle_data['Parameters'].keys()}\n",
    "\n",
    "        for key, data in pickle_data['Parameters'].items():\n",
    "                key_arrays[key].append(data)\n",
    "        \n",
    "    mu = []\n",
    "    std = []\n",
    "\n",
    "    for key, data in key_arrays.items():\n",
    "        key_arrays[key] = np.array(sum(key_arrays[key], []))\n",
    "        mu.append(float(f'{np.mean(key_arrays[key]):0.4f}'))\n",
    "        std.append(float(f'{np.std(key_arrays[key]):0.4f}'))\n",
    "\n",
    "    print(f\"mu = {mu}\")\n",
    "    print(f\"std = {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_and_dev(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'analyses/2source_gamma2.0_mcmc_sumscale_trials10_1season_run2'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = name_func(n_sources=2, gamma=2.0, min_type='mcmc', \n",
    "                 scale='sumscale', trials=10, etc='1season')\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mh_dict = {\n",
    "    \"name\": name,                                           # unique name for the analysis\n",
    "    \"mh_name\": \"fit_weights_mcmc\",                          # name of the MinimisationHandler subclass\n",
    "    \"dataset\": icecube_ps_3_year.get_seasons('IC79-2010'),  # the neutrino dataset\n",
    "    \"catalogue\": catalogue_path,                            # path to the .npy catalogue file\n",
    "    \"inj_dict\": inj_kwargs,                                 # info for the Injector\n",
    "    \"llh_dict\": llh_kwargs,                                 # info for the LLH\n",
    "    \"scale\": np.sum(scale),                                 # a guess for the sensitivity scale\n",
    "    \"n_trials\": 10,                                         # number of trials to run (background trials will be run ten times this number!)\n",
    "    \"n_steps\": 10,                                          # number of steps when injecting signal\n",
    "    \"allow_extrapolated_sensitivity\": True                  # allow extrapolation in the sensitivity calculation (here we do because we only run very few trials)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:flarestack.cluster.submitter:No submitter implemented for host server None! Using LocalSubmitter but you wont't be able to use cluster operations!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Submitter for analyses/2source_gamma2.0_mcmc_sumscale_trials10_1season_run2 -----\n",
      "not using cluster \n",
      "using 7 CPUs locally\n",
      "job-id: None \n",
      "no scale estimation \n",
      "\n"
     ]
    }
   ],
   "source": [
    "submitter = Submitter.get_submitter(\n",
    "    mh_dict=mh_dict,                         # the analysis info\n",
    "    use_cluster=False,                       # run it on the cluster if True\n",
    "    n_cpu=7,                                # number of LOCAL CPUs to use, NOTE: the number of cluster CPUs has to be specified in the cluster_kwargs!\n",
    "    do_sensitivity_scale_estimation=False,   # make a guess of the sensitivity scale, for options check flarestack.cluster.submitter\n",
    "    remove_old_results=True,                 # if you are running the analysis again and something changed, maybe you want to remove old trials?\n",
    "#   **cluster_kwargs                         # keyword arguments used when running the cluster, This depends on the cluster obviously\n",
    ")\n",
    "\n",
    "print(submitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:flarestack.cluster.submitter:Can not remove /Users/thomasahrens/Desktop/IceCube/flarestack/scratch/flarestack__data/storage/pickles/analyses/2source_gamma2.0_mcmc_sumscale_trials10_1season_run2! It is not a directory!\n",
      "WARNING:flarestack.cluster.submitter:Can not remove /Users/thomasahrens/Desktop/IceCube/flarestack/scratch/flarestack__data/storage/pickles/injection_values/analyses/2source_gamma2.0_mcmc_sumscale_trials10_1season_run2! It is not a directory!\n",
      "INFO:flarestack.core.minimisation:Using 'standard' LLH class\n",
      "INFO:flarestack.core.injector:Initialising Injector for IC79-2010\n",
      "INFO:flarestack.core.minimisation:Using 'standard' LLH class\n",
      "INFO:flarestack.core.minimisation:Using 'standard' LLH class\n",
      "INFO:flarestack.core.minimisation:Using 'standard' LLH class\n",
      "INFO:flarestack.core.minimisation:Using 'standard' LLH class\n",
      "INFO:flarestack.core.minimisation:Using 'standard' LLH class\n",
      "INFO:flarestack.core.minimisation:Using 'standard' LLH class\n",
      "INFO:flarestack.core.multiprocess_wrapper:Added 190 trials to queue. Now processing.\n",
      "INFO:flarestack.core.minimisation:Using 'standard' LLH class\n",
      "INFO:flarestack.core.multiprocess_wrapper:190 tasks remaining.\n",
      "/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/llh.py:912: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  kwargs[\"SoB_spacetime_cache\"] = np.array(SoB_spacetime)\n",
      "/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/llh.py:912: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  kwargs[\"SoB_spacetime_cache\"] = np.array(SoB_spacetime)\n",
      "/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/llh.py:912: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  kwargs[\"SoB_spacetime_cache\"] = np.array(SoB_spacetime)\n",
      "/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/llh.py:912: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  kwargs[\"SoB_spacetime_cache\"] = np.array(SoB_spacetime)\n",
      "/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/llh.py:912: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  kwargs[\"SoB_spacetime_cache\"] = np.array(SoB_spacetime)\n",
      "/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/llh.py:912: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  kwargs[\"SoB_spacetime_cache\"] = np.array(SoB_spacetime)\n",
      "/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/moves/red_blue.py:99: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  lnpdiff = f + nlp - state.log_prob[j]\n",
      "/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/llh.py:912: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  kwargs[\"SoB_spacetime_cache\"] = np.array(SoB_spacetime)\n",
      "/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/moves/red_blue.py:99: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  lnpdiff = f + nlp - state.log_prob[j]\n",
      "/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/moves/red_blue.py:99: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  lnpdiff = f + nlp - state.log_prob[j]\n",
      "/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/moves/red_blue.py:99: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  lnpdiff = f + nlp - state.log_prob[j]\n",
      "/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/moves/red_blue.py:99: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  lnpdiff = f + nlp - state.log_prob[j]\n",
      "/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/moves/red_blue.py:99: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  lnpdiff = f + nlp - state.log_prob[j]\n",
      "/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/moves/red_blue.py:99: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  lnpdiff = f + nlp - state.log_prob[j]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emcee: Exception while calling your likelihood function:emcee: Exception while calling your likelihood function:emcee: Exception while calling your likelihood function:emcee: Exception while calling your likelihood function:emcee: Exception while calling your likelihood function:emcee: Exception while calling your likelihood function:emcee: Exception while calling your likelihood function:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  params:  params:  params:  params:  params:  params:   params:      [2.00394938 4.1743923  3.97508037][2.34202253 0.21356181 2.87877378][1.51781515 0.62671558 2.99515696][0.46425674 0.60403723 2.24508564][0.30964751 0.64051086 1.61109662]\n",
      "[0.19216292 3.10292342 1.65382629]\n",
      "\n",
      "\n",
      "[6.44442462 6.83997766 3.62736517]  args:\n",
      "\n",
      "  args:  args:  args:\n",
      "  args:   args:     args: [] [][][] []\n",
      "[]\n",
      "\n",
      "\n",
      "[]\n",
      "\n",
      "  kwargs:  kwargs:  kwargs:  kwargs:  kwargs:\n",
      "   kwargs:      kwargs:{} {}{}{} {}\n",
      "\n",
      "{}\n",
      "\n",
      "\n",
      "  exception:{}\n",
      "  exception:  exception:  exception:  exception:\n",
      "\n",
      "\n",
      "\n",
      "  exception:\n",
      "\n",
      "  exception:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/ensemble.py\", line 624, in __call__\n",
      "    return self.f(x, *self.args, **self.kwargs)\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/ensemble.py\", line 624, in __call__\n",
      "    return self.f(x, *self.args, **self.kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/ensemble.py\", line 624, in __call__\n",
      "    return self.f(x, *self.args, **self.kwargs)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1625, in log_prob\n",
      "    return -l_prior + log_llh(params)\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/ensemble.py\", line 624, in __call__\n",
      "    return self.f(x, *self.args, **self.kwargs)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1625, in log_prob\n",
      "    return -l_prior + log_llh(params)\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/ensemble.py\", line 624, in __call__\n",
      "    return self.f(x, *self.args, **self.kwargs)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1625, in log_prob\n",
      "    return -l_prior + log_llh(params)\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/ensemble.py\", line 624, in __call__\n",
      "    return self.f(x, *self.args, **self.kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1589, in log_llh\n",
      "    return np.sum(raw_f(params))\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1625, in log_prob\n",
      "    return -l_prior + log_llh(params)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1589, in log_llh\n",
      "    return np.sum(raw_f(params))\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1625, in log_prob\n",
      "    return -l_prior + log_llh(params)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1398, in f_final\n",
      "    for i, name in enumerate(self.seasons):\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1625, in log_prob\n",
      "    return -l_prior + log_llh(params)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1589, in log_llh\n",
      "    return np.sum(raw_f(params))\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/ensemble.py\", line 624, in __call__\n",
      "    return self.f(x, *self.args, **self.kwargs)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1589, in log_llh\n",
      "    return np.sum(raw_f(params))\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1400, in f_final\n",
      "    ts_val += llh_functions[name](params, w)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1589, in log_llh\n",
      "    return np.sum(raw_f(params))\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/data/__init__.py\", line 91, in __iter__\n",
      "    def __iter__(self):\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1589, in log_llh\n",
      "    return np.sum(raw_f(params))\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1625, in log_prob\n",
      "    return -l_prior + log_llh(params)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1400, in f_final\n",
      "    ts_val += llh_functions[name](params, w)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1388, in f_final\n",
      "    weights_matrix = self.make_weight_matrix(params)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/llh.py\", line 344, in test_statistic\n",
      "    return self.calculate_test_statistic(params, weights, **kwargs)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1400, in f_final\n",
      "    ts_val += llh_functions[name](params, w)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1388, in f_final\n",
      "    weights_matrix = self.make_weight_matrix(params)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 714, in make_weight_matrix\n",
      "    weights_matrix = np.ones([len(self.seasons), len(self.sources)])\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/llh.py\", line 344, in test_statistic\n",
      "    return self.calculate_test_statistic(params, weights, **kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1589, in log_llh\n",
      "    return np.sum(raw_f(params))\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/llh.py\", line 344, in test_statistic\n",
      "    return self.calculate_test_statistic(params, weights, **kwargs)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/llh.py\", line 971, in calculate_test_statistic\n",
      "    if np.sum([np.sum(x_row <= 0.0) for x_row in x]) > 0:\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/numpy/core/numeric.py\", line 205, in ones\n",
      "    multiarray.copyto(a, 1, casting='unsafe')\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 717, in make_weight_matrix\n",
      "    w = self.make_season_weight(params, season)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/llh.py\", line 978, in calculate_test_statistic\n",
      "    llh_value += np.sum(\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1400, in f_final\n",
      "    ts_val += llh_functions[name](params, w)\n",
      "Process Process-6:\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/llh.py\", line 971, in <listcomp>\n",
      "    if np.sum([np.sum(x_row <= 0.0) for x_row in x]) > 0:\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/llh.py\", line 985, in calculate_test_statistic\n",
      "    np.sum(all_n_j) < 0, np.sum(llh_value) < np.sum(-50.0 + all_n_j)\n",
      "  File \"<__array_function__ internals>\", line 179, in copyto\n",
      "  File \"<__array_function__ internals>\", line 180, in sum\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 690, in make_season_weight\n",
      "    time_weights.append(llh.sig_time_pdf.effective_injection_time(source))\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/llh.py\", line 344, in test_statistic\n",
      "    return self.calculate_test_statistic(params, weights, **kwargs)\n",
      "  File \"<__array_function__ internals>\", line 177, in sum\n",
      "  File \"<__array_function__ internals>\", line 177, in sum\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/numpy/core/multiarray.py\", line 1071, in copyto\n",
      "    @array_function_from_c_func_and_dispatcher(_multiarray_umath.copyto)\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/numpy/core/fromnumeric.py\", line 2296, in sum\n",
      "    return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/time_pdf.py\", line 325, in effective_injection_time\n",
      "    season_length = self.integral_to_infinity(source) * self.livetime\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/numpy/core/fromnumeric.py\", line 84, in _wrapreduction\n",
      "    return reduction(axis=axis, out=out, **passkwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/llh.py\", line 976, in calculate_test_statistic\n",
      "    llh_value = np.sum([np.sum(np.log(y)) for y in x])\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/time_pdf.py\", line 231, in integral_to_infinity\n",
      "    max_int = self.product_integral(self.sig_t1(source), source)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/numpy/core/_methods.py\", line 46, in _sum\n",
      "    def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "Process Process-3:\n",
      "Process Process-1:\n",
      "Process Process-5:\n",
      "  File \"<__array_function__ internals>\", line 180, in sum\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/multiprocess_wrapper.py\", line 102, in run_trial\n",
      "    mpmh.run_single(full_dataset, scale, seed)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/numpy/core/fromnumeric.py\", line 2296, in sum\n",
      "    return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 555, in run_single\n",
      "    res_dict = self.run_trial(full_dataset)\n",
      "Process Process-2:\n",
      "Process Process-4:\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/numpy/core/fromnumeric.py\", line 73, in _wrapreduction\n",
      "    if type(obj) is not mu.ndarray:\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1659, in run_trial\n",
      "    chain = run_emcee_convergence(verbose=False)\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/multiprocess_wrapper.py\", line 102, in run_trial\n",
      "    mpmh.run_single(full_dataset, scale, seed)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1638, in run_emcee_convergence\n",
      "    sampler.run_mcmc(begin, nsteps=batchsize, progress=verbose)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/multiprocess_wrapper.py\", line 102, in run_trial\n",
      "    mpmh.run_single(full_dataset, scale, seed)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/multiprocess_wrapper.py\", line 102, in run_trial\n",
      "    mpmh.run_single(full_dataset, scale, seed)\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 555, in run_single\n",
      "    res_dict = self.run_trial(full_dataset)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 555, in run_single\n",
      "    res_dict = self.run_trial(full_dataset)\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/ensemble.py\", line 443, in run_mcmc\n",
      "    for results in self.sample(initial_state, iterations=nsteps, **kwargs):\n",
      "Process Process-7:\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 555, in run_single\n",
      "    res_dict = self.run_trial(full_dataset)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1659, in run_trial\n",
      "    chain = run_emcee_convergence(verbose=False)\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/ensemble.py\", line 402, in sample\n",
      "    state, accepted = move.propose(model, state)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1659, in run_trial\n",
      "    chain = run_emcee_convergence(verbose=False)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/multiprocess_wrapper.py\", line 102, in run_trial\n",
      "    mpmh.run_single(full_dataset, scale, seed)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1659, in run_trial\n",
      "    chain = run_emcee_convergence(verbose=False)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/multiprocess_wrapper.py\", line 102, in run_trial\n",
      "    mpmh.run_single(full_dataset, scale, seed)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1638, in run_emcee_convergence\n",
      "    sampler.run_mcmc(begin, nsteps=batchsize, progress=verbose)\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/moves/red_blue.py\", line 93, in propose\n",
      "    new_log_probs, new_blobs = model.compute_log_prob_fn(q)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 555, in run_single\n",
      "    res_dict = self.run_trial(full_dataset)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1638, in run_emcee_convergence\n",
      "    sampler.run_mcmc(begin, nsteps=batchsize, progress=verbose)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1638, in run_emcee_convergence\n",
      "    sampler.run_mcmc(begin, nsteps=batchsize, progress=verbose)\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/ensemble.py\", line 443, in run_mcmc\n",
      "    for results in self.sample(initial_state, iterations=nsteps, **kwargs):\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 555, in run_single\n",
      "    res_dict = self.run_trial(full_dataset)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1659, in run_trial\n",
      "    chain = run_emcee_convergence(verbose=False)\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/ensemble.py\", line 489, in compute_log_prob\n",
      "    results = list(map_func(self.log_prob_fn, p))\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/ensemble.py\", line 443, in run_mcmc\n",
      "    for results in self.sample(initial_state, iterations=nsteps, **kwargs):\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/ensemble.py\", line 402, in sample\n",
      "    state, accepted = move.propose(model, state)\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/ensemble.py\", line 443, in run_mcmc\n",
      "    for results in self.sample(initial_state, iterations=nsteps, **kwargs):\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1659, in run_trial\n",
      "    chain = run_emcee_convergence(verbose=False)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1638, in run_emcee_convergence\n",
      "    sampler.run_mcmc(begin, nsteps=batchsize, progress=verbose)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/moves/red_blue.py\", line 93, in propose\n",
      "    new_log_probs, new_blobs = model.compute_log_prob_fn(q)\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/ensemble.py\", line 624, in __call__\n",
      "    return self.f(x, *self.args, **self.kwargs)\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/ensemble.py\", line 402, in sample\n",
      "    state, accepted = move.propose(model, state)\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/ensemble.py\", line 402, in sample\n",
      "    state, accepted = move.propose(model, state)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/multiprocess_wrapper.py\", line 102, in run_trial\n",
      "    mpmh.run_single(full_dataset, scale, seed)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1638, in run_emcee_convergence\n",
      "    sampler.run_mcmc(begin, nsteps=batchsize, progress=verbose)\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/ensemble.py\", line 443, in run_mcmc\n",
      "    for results in self.sample(initial_state, iterations=nsteps, **kwargs):\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/ensemble.py\", line 489, in compute_log_prob\n",
      "    results = list(map_func(self.log_prob_fn, p))\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1625, in log_prob\n",
      "    return -l_prior + log_llh(params)\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/moves/red_blue.py\", line 93, in propose\n",
      "    new_log_probs, new_blobs = model.compute_log_prob_fn(q)\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/moves/red_blue.py\", line 93, in propose\n",
      "    new_log_probs, new_blobs = model.compute_log_prob_fn(q)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 555, in run_single\n",
      "    res_dict = self.run_trial(full_dataset)\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/ensemble.py\", line 443, in run_mcmc\n",
      "    for results in self.sample(initial_state, iterations=nsteps, **kwargs):\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/ensemble.py\", line 402, in sample\n",
      "    state, accepted = move.propose(model, state)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1589, in log_llh\n",
      "    return np.sum(raw_f(params))\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/ensemble.py\", line 489, in compute_log_prob\n",
      "    results = list(map_func(self.log_prob_fn, p))\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/ensemble.py\", line 624, in __call__\n",
      "    return self.f(x, *self.args, **self.kwargs)\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/ensemble.py\", line 489, in compute_log_prob\n",
      "    results = list(map_func(self.log_prob_fn, p))\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1659, in run_trial\n",
      "    chain = run_emcee_convergence(verbose=False)\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/ensemble.py\", line 402, in sample\n",
      "    state, accepted = move.propose(model, state)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1398, in f_final\n",
      "    for i, name in enumerate(self.seasons):\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/moves/red_blue.py\", line 93, in propose\n",
      "    new_log_probs, new_blobs = model.compute_log_prob_fn(q)\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/ensemble.py\", line 624, in __call__\n",
      "    return self.f(x, *self.args, **self.kwargs)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1625, in log_prob\n",
      "    return -l_prior + log_llh(params)\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/ensemble.py\", line 624, in __call__\n",
      "    return self.f(x, *self.args, **self.kwargs)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/data/__init__.py\", line 91, in __iter__\n",
      "    def __iter__(self):\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1638, in run_emcee_convergence\n",
      "    sampler.run_mcmc(begin, nsteps=batchsize, progress=verbose)\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/ensemble.py\", line 489, in compute_log_prob\n",
      "    results = list(map_func(self.log_prob_fn, p))\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/moves/red_blue.py\", line 93, in propose\n",
      "    new_log_probs, new_blobs = model.compute_log_prob_fn(q)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1625, in log_prob\n",
      "    return -l_prior + log_llh(params)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1625, in log_prob\n",
      "    return -l_prior + log_llh(params)\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/ensemble.py\", line 624, in __call__\n",
      "    return self.f(x, *self.args, **self.kwargs)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1589, in log_llh\n",
      "    return np.sum(raw_f(params))\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/ensemble.py\", line 443, in run_mcmc\n",
      "    for results in self.sample(initial_state, iterations=nsteps, **kwargs):\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/ensemble.py\", line 489, in compute_log_prob\n",
      "    results = list(map_func(self.log_prob_fn, p))\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1589, in log_llh\n",
      "    return np.sum(raw_f(params))\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1589, in log_llh\n",
      "    return np.sum(raw_f(params))\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1625, in log_prob\n",
      "    return -l_prior + log_llh(params)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1388, in f_final\n",
      "    weights_matrix = self.make_weight_matrix(params)\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/ensemble.py\", line 402, in sample\n",
      "    state, accepted = move.propose(model, state)\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/ensemble.py\", line 624, in __call__\n",
      "    return self.f(x, *self.args, **self.kwargs)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1400, in f_final\n",
      "    ts_val += llh_functions[name](params, w)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1400, in f_final\n",
      "    ts_val += llh_functions[name](params, w)\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/moves/red_blue.py\", line 93, in propose\n",
      "    new_log_probs, new_blobs = model.compute_log_prob_fn(q)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 714, in make_weight_matrix\n",
      "    weights_matrix = np.ones([len(self.seasons), len(self.sources)])\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1589, in log_llh\n",
      "    return np.sum(raw_f(params))\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/llh.py\", line 344, in test_statistic\n",
      "    return self.calculate_test_statistic(params, weights, **kwargs)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1625, in log_prob\n",
      "    return -l_prior + log_llh(params)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/llh.py\", line 344, in test_statistic\n",
      "    return self.calculate_test_statistic(params, weights, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/ensemble.py\", line 489, in compute_log_prob\n",
      "    results = list(map_func(self.log_prob_fn, p))\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/numpy/core/numeric.py\", line 205, in ones\n",
      "    multiarray.copyto(a, 1, casting='unsafe')\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1400, in f_final\n",
      "    ts_val += llh_functions[name](params, w)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1589, in log_llh\n",
      "    return np.sum(raw_f(params))\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/llh.py\", line 985, in calculate_test_statistic\n",
      "    np.sum(all_n_j) < 0, np.sum(llh_value) < np.sum(-50.0 + all_n_j)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/llh.py\", line 971, in calculate_test_statistic\n",
      "    if np.sum([np.sum(x_row <= 0.0) for x_row in x]) > 0:\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/emcee/ensemble.py\", line 624, in __call__\n",
      "    return self.f(x, *self.args, **self.kwargs)\n",
      "  File \"<__array_function__ internals>\", line 179, in copyto\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/llh.py\", line 344, in test_statistic\n",
      "    return self.calculate_test_statistic(params, weights, **kwargs)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1388, in f_final\n",
      "    weights_matrix = self.make_weight_matrix(params)\n",
      "  File \"<__array_function__ internals>\", line 177, in sum\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/llh.py\", line 971, in <listcomp>\n",
      "    if np.sum([np.sum(x_row <= 0.0) for x_row in x]) > 0:\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/numpy/core/multiarray.py\", line 1071, in copyto\n",
      "    @array_function_from_c_func_and_dispatcher(_multiarray_umath.copyto)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1625, in log_prob\n",
      "    return -l_prior + log_llh(params)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/llh.py\", line 978, in calculate_test_statistic\n",
      "    llh_value += np.sum(\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 717, in make_weight_matrix\n",
      "    w = self.make_season_weight(params, season)\n",
      "  File \"<__array_function__ internals>\", line 177, in sum\n",
      "KeyboardInterrupt\n",
      "  File \"<__array_function__ internals>\", line 180, in sum\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1589, in log_llh\n",
      "    return np.sum(raw_f(params))\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 690, in make_season_weight\n",
      "    time_weights.append(llh.sig_time_pdf.effective_injection_time(source))\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/numpy/core/fromnumeric.py\", line 2296, in sum\n",
      "    return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/minimisation.py\", line 1400, in f_final\n",
      "    ts_val += llh_functions[name](params, w)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/time_pdf.py\", line 325, in effective_injection_time\n",
      "    season_length = self.integral_to_infinity(source) * self.livetime\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/numpy/core/fromnumeric.py\", line 84, in _wrapreduction\n",
      "    return reduction(axis=axis, out=out, **passkwargs)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/llh.py\", line 344, in test_statistic\n",
      "    return self.calculate_test_statistic(params, weights, **kwargs)\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/time_pdf.py\", line 231, in integral_to_infinity\n",
      "    max_int = self.product_integral(self.sig_t1(source), source)\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/numpy/core/_methods.py\", line 46, in _sum\n",
      "    def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "  File \"/Users/thomasahrens/Desktop/IceCube/flarestack/flarestack/core/llh.py\", line 976, in calculate_test_statistic\n",
      "    llh_value = np.sum([np.sum(np.log(y)) for y in x])\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"<__array_function__ internals>\", line 180, in sum\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/numpy/core/fromnumeric.py\", line 2296, in sum\n",
      "    return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n",
      "  File \"/Users/thomasahrens/opt/anaconda3/envs/hesnu/lib/python3.10/site-packages/numpy/core/fromnumeric.py\", line 73, in _wrapreduction\n",
      "    if type(obj) is not mu.ndarray:\n",
      "KeyboardInterrupt\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "submitter.analyse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flarestack.core.results import ResultsHandler\n",
    "results_handler_mcmc = ResultsHandler(submitter.mh_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fr'sensitivity flux: {results_handler_mcmc.sensitivity:<10.2e} '\n",
    "      fr'+{results_handler_mcmc.sensitivity_err[1]:<10.2e} '\n",
    "      fr'-{results_handler_mcmc.sensitivity_err[0]:<10.2e}')\n",
    "print(f'reference: {reference_sensitivity(sindec)[0]:>15.2e}')\n",
    "print(fr'sensitivity n_s:  {results_handler_mcmc.sensitivity * results_handler_mcmc.flux_to_ns:<10.2e} '\n",
    "      fr'+{results_handler_mcmc.sensitivity_err[1] * results_handler_mcmc.flux_to_ns:<9.4f}  '\n",
    "      fr'-{results_handler_mcmc.sensitivity_err[0] * results_handler_mcmc.flux_to_ns:<9.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. MCMC Analysis Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import corner\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mcmc_pickle_path = os.path.join(name_pickle_output_dir(name), 'chains.pkl')\n",
    "\n",
    "with open(mcmc_pickle_path, 'rb') as file:\n",
    "    mcmc_pickle = pickle.load(file)\n",
    "    \n",
    "mcmc_pickle.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels(name):\n",
    "    corner_labels = []\n",
    "    for source in range(len(catalogue)):\n",
    "        corner_label = catalogue[source]['source_name'].decode()\n",
    "        corner_labels.append('n_s: ' + corner_label)\n",
    "    corner_labels.append('gamma')\n",
    "    \n",
    "    return corner_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corner Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corner_plot(name, save_fig=False, **kwargs):\n",
    "    \n",
    "    corner_labels = labels(name)\n",
    "\n",
    "    truths = np.append(scale / 3, injection_energy['gamma'])\n",
    "    \n",
    "    corner_kwargs = dict(\n",
    "        bins=30,\n",
    "        labels=corner_labels,\n",
    "        quantiles=[0.16, 0.5, 0.84],\n",
    "        truths=truths,\n",
    "        use_math_text=True,\n",
    "        show_titles=True, \n",
    "        title_kwargs={\"fontsize\": 10},\n",
    "        truth_color='#4682b4',\n",
    "        plot_datapoints=False, \n",
    "        fill_contours=True,\n",
    "    )\n",
    "    \n",
    "    for key, value in kwargs.items():\n",
    "        corner_kwargs[key] = value\n",
    "    \n",
    "    ndim = len(catalogue) + 1\n",
    "    \n",
    "    reshaped_steps = mcmc_pickle.reshape((-1,ndim))\n",
    "    \n",
    "    fig = corner.corner(reshaped_steps, \n",
    "                        **corner_kwargs)\n",
    "    \n",
    "    if save_fig:\n",
    "        plt.savefig(os.path.join(plot_output_dir(name), 'corner.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corner_plot(name, save_fig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Walker Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walker_plot(name, n_steps=len(mcmc_pickle), save_fig=False):\n",
    "    ndim = len(catalogue) + 1\n",
    "    fig, axes = plt.subplots(ndim, figsize=(15, 8), sharex=True)\n",
    "    # samples = sampler.get_chain()\n",
    "    walker_labels = labels(name)\n",
    "    for i in range(ndim):\n",
    "        ax = axes[i]\n",
    "        ax.plot(mcmc_pickle[:, :, i], \"k\", alpha=0.1)\n",
    "        ax.set_xlim(0, len(mcmc_pickle[:n_steps]))\n",
    "        ax.set_ylabel(walker_labels[i], rotation=0, ha='right')\n",
    "        ax.yaxis.set_label_coords(-0.05, 0.5)\n",
    "\n",
    "    axes[-1].set_xlabel(\"step number\")\n",
    "    fig.tight_layout\n",
    "    \n",
    "    if save_fig:\n",
    "        plt.savefig(os.path.join(plot_output_dir(name), 'walkers.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walker_plot(name, save_fig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
